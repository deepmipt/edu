---
layout: post
title: Проекты учаcтников семинара
---

На текущий моментесть три задачи от сотрудников нашей лаборатории, которые заинтересованы в вашей помощи:

1) *Named Entity Recognition with Noise*
Real data, like Twitter is always noisy, let’s find out, how the noise is corrupting results of NER.
There are SotA architectures, like LSTM + CRF. 
Possible options to try also: 
* SRU
* QRNN
* CNN

Pros: 
* Clear path to results
* Clear metrics
* Real-world problem

Cons:
* A lot of work in the field, but still there is a space to improvement.

References:
https://arxiv.org/abs/1603.01354 

Social media papers:
Snap:
https://arxiv.org/abs/1802.07862
Twitter:
https://arxiv.org/abs/1710.11027
https://www.aclweb.org/anthology/W/W17/W17-4419.pdf
https://cocoxu.github.io/publications/wnut2015_overview.pdf
The ritter dataset: https://homes.cs.washington.edu/~mausam/papers/emnlp11.pdf


2) *Метрика качества диалогов*
Чатбот – программа, которая может вести беседу с пользователем на свободную тему. Оценить качество работы чатбота автоматически очень сложно. Главная проблема в том, что в задаче ведения диалога нет “правильного” ответа, с которым можно сравнить то, что выдала система. Поэтому метрики, которые используются для определения качества машинного перевода, в данном случае не подходят. 
При этом человек легко может оценить качества бота: ему достаточно прочитать выданный системой ответ, чтобы понять, встраивается ли он в диалог. Теперь наша задача в том, чтобы научиться делать это без участия человека. Мы собрали корпус диалогов человека с ботом, каждый диалог оценен человеком по пятибалльной шкале. Эти данные нужно использовать, чтобы обучить метрику для чатботов. Предполагается, что, проанализировав эти размеченные данные, метрика выделит признаки хороших и плохих диалогов, и сможет найти их в новых диалогах.
Более подробная и постановка задачи и список литературы здесь: https://drive.google.com/open?id=1YzBqvrvMD_6HRZumZsadzxwnCyP-c1Bd 

3) *GAN language generation*
Основная идея заключается в обучении языковой модели (нейросетевая архитектура моделирующая некий естественный язык) при помощи GAN \[https://arxiv.org/pdf/1406.2661.pdf\] (что в принципе уже сделано). И в дальнейшем попытаться научиться управлять тем, что она генерирует (стилем, тематической областью, и т.д.), попытаться обучить таким образом вопросно-ответную систему. Проверить насколько обученный дискриминатор от такой модели может коррелировать с BLEU, и вообще применяться для оценивания качества искусственно генерируемого текста. И т.д. 

Задачи, или что в принципе надо делать:
* Для начала надо воспроизвести результаты статьи Adversarial Generation of Natural Language \[https://arxiv.org/pdf/1705.10929v1.pdf\]. При исполнении данной задачи появится понимание (на практике) о том что вообще такое GAN, и с чем его употребляют. Почему у GAN с самого начала были проблемы с текстовыми данными, а также возможность разобраться с seq2seq моделями, и с тем как их прогают на tensorflow.
* Провести эксперименты в которых генератор обучался бы сразу нескольким стилям написания текста (например стихи и проза). Или обучение генерации в разных тематических областях (например научные статьи и рекламные описания бижутерии (данные примеры мало относятся к реальности, главное чтобы была понятна суть)). И попытаться потом этим управлять, как например в статье от deepmind WAVENET \[https://arxiv.org/pdf/1609.03499.pdf\].
* Можно попытаться построить диалоговую систему, иначе говоря попробовать запихнуть в простой seq2seq chilchat какую-то семантику. Например на диалогах. А дополнительную информацию можно запихнуть через дискриминатор. Также и с вопросно-ответной системой. За базовый вариант можно взять FAQ с сайта, или ответы с mail.ru, или типа того. И попытаться заставить генератор отвечать на вопросы. 


